:PROPERTIES:
:ID:       f01bad77-3241-4ba5-ab40-89dafdfe1b97
:END:
#+title: ai blackbox is a competition gimmick
#+cite_export: csl /home/kjani/Zotero/styles/oscola.csl

The blackbox problem states that by letting models use experiential learning, we have lost track of understanding /how/ does the model actual develop an inference.[cite:@AIsMysteriousBlack] Its opaque nature is most concerning when the model makes a mistake as it can only be /inferred/ as to why such a mistake was made of which there is no certainty.

Rudin highlights that conversely there are glassbox models also which are called interpretable models.[cite:@rudinWhyAreWe2019] There is a general misconception that these models prioritise transparency at the expense of efficiency. Rudin disapproves primarily because the glassbox model can be easily fine-tuned for mistakes making it a better long-term deployment than a blackbox model. 

The cause of using such models like everything comes down to money and control. While interpretable models are far more simple to replicate, blackbox ai is proprietary with only the creator having any clue as to what part of the training data could have triggered such an outcome. This control allows developers to rope in hook customers. 
